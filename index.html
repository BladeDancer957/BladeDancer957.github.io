<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Duzhen Zhang (张笃振)</title>

  <meta name="author" content="Duzhen Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/avatar.jpg">


<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Duzhen Zhang (张笃振)</name>
                  </p>

                  <p align="justify">
                    My Chinese name is 张(Zhang)笃(Du)振(Zhen). 
                    I am a PhD student (2019.9 - 2024.6.(expected)) in artificial intelligence at <a href="http://english.ia.cas.cn/" target="_blank" rel="noopener">CASIA</a> advised by <a href="http://english.ia.cas.cn/en_sourcedb_ia/iaexpert/202310/t20231031_455698.html" target="_blank" rel="noopener">Bo Xu</a> and <a href="https://braincog.ai/~tielin.zhang/" target="_blank" rel="noopener">Tielin Zhang</a>. 
                    Prior to that, I received my bachelor degree at Shandong University (2015.9. - 2019.6.).
                  </p>

                  <p align="justify">
                    Previously, my research interests included Emotion Analysis in Conversations, Incremental/Federated Learning and Its Applications in Information Extraction, and Brain­-inspired Intelligence. Now, I'm currently working on Continual Learning in LLMs, Large Multi-Modal Model, and Applications of LLMs.
                  </p>

                  <p align="justify">
                    I am looking for <font color="red">cooperation</font>. Contact me if you are interested in the above topics.
                  </p>


                  <p align="justify">
                    I am actively seeking a <font color="red">postdoctoral position</font> as well. If you are interested in my experience, please feel free to contact me and let me know.
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:zhangduzhen2019@ia.ac.cn">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com.hk/citations?user=o0jlAfwAAAAJ&hl=zh-CN">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/BladeDancer957"> GitHub </a> &nbsp/&nbsp
                    <a href="https://weibo.com/u/6984959147"> Weibo </a> &nbsp/&nbsp
                    <a href="https://www.xiaohongshu.com/user/profile/5d3ecbf30000000011005f67"> XiaoHongShu </a> &nbsp/&nbsp
                    <a href="docs/简历.pdf"> Resumé (PDF) </a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="#"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar.jpg"
                      class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr>
                <td style="padding:25px;width:35%;vertical-align:middle">
                  <div class="one">
                    <img src='images/11.png' width="250">
                  </div>
                </td>
                <td style="padding:25px;width:70%;vertical-align:middle">
                  <a href="">
                    <papertitle>Tuning Synaptic Connections instead of Weights by Genetic Algorithm in Spiking Policy Network
                    </papertitle>
                  </a>
                  <br /><br />
                  <strong>Duzhen Zhang</strong>,
                  Tielin Zhang,
                  Shuncheng Jia,
                  Qingyu Wang,
                  Bo Xu,
                  <br /><br />
                  <strong>Machine Intelligence Research</strong>
                  <br>
                  <a href="https://arxiv.org/abs/2301.10292">Paper</a>
                  <a href="https://github.com/BladeDancer957/SPN-GA">Code</a>
                  <p align="justify">
                    Learning from the interaction is the primary way biological agents know about the environment and themselves. Modern deep reinforcement learning (DRL) explores a computational approach to learning from interaction and has significantly progressed in solving various tasks. However, the powerful DRL is still far from biological agents in energy efficiency. Although the underlying mechanisms are not fully understood, we believe that the integration of spiking communication between neurons and biologically-plausible synaptic plasticity plays a prominent role. Following this biological intuition, we optimize a spiking policy network (SPN) by a genetic algorithm as an energy-efficient alternative to DRL. Our SPN mimics the sensorimotor neuron pathway of insects and communicates through event-based spikes. Inspired by biological research that the brain forms memories by forming new synaptic connections and rewires these connections based on new experiences, we tune the synaptic connections instead of weights in SPN to solve given tasks. Experimental results on several robotic control tasks show that our method can achieve the performance level of mainstream DRL methods and exhibit significantly higher energy efficiency.
                  </p>

                  </p>
                </td>
              </tr>


              <tr>
                <td style="padding:25px;width:35%;vertical-align:middle">
                  <div class="one">
                    <img src='images/8.png' width="250">
                  </div>
                </td>
                <td style="padding:25px;width:70%;vertical-align:middle">
                  <a href="">
                    <papertitle>Continual Named Entity Recognition without Catastrophic Forgetting
                    </papertitle>
                  </a>
                  <br /><br />
                  <strong>Duzhen Zhang</strong>,
                  Wei Cong,
                  Jiahua Dong,
                  Yahan Yu,
                  Xiuyi Chen,
                  <br>
                  Yonggang Zhang,
                  Zhen Fang
                  <br /><br />
                  <strong>EMNLP2023</strong>
                  <br>
                  <a href="https://arxiv.org/abs/2310.14541">Paper</a>
                  <a href="https://github.com/BladeDancer957/CPFD">Code</a>
                  <a href="posters/EMNLP2023_Poster.pdf">Poster</a>
                  <a href="slides/EMNLP2023_Presentation.pdf">Slide</a>
      
                  <p align="justify">
                    Continual Named Entity Recognition (CNER) is a burgeoning area, which involves updating an existing model by incorporating new entity types sequentially. Nevertheless, continual learning approaches are often severely afflicted by catastrophic forgetting. This issue is intensified in CNER due to the consolidation of old entity types from previous steps into the non-entity type at each step, leading to what is known as the semantic shift problem of the non-entity type. In this paper, we introduce a pooled feature distillation loss that skillfully navigates the trade-off between retaining knowledge of old entity types and acquiring new ones, thereby more effectively mitigating the problem of catastrophic forgetting. Additionally, we develop a confidence-based pseudo-labeling for the non-entity type, \emph{i.e.,} predicting entity types using the old model to handle the semantic shift of the non-entity type. Following the pseudo-labeling process, we suggest an adaptive re-weighting type-balanced learning strategy to handle the issue of biased type distribution. We carried out comprehensive experiments on ten CNER settings using three different datasets. The results illustrate that our method significantly outperforms prior state-of-the-art approaches, registering an average improvement of 6.3\% and 8.0\% in Micro and Macro F1 scores, respectively.
                  </p>
                </td>
              </tr>


              <tr>
                <td style="padding:25px;width:35%;vertical-align:middle">
                  <div class="one">
                    <img src='images/6.png' width="250">
                  </div>
                </td>
                <td style="padding:25px;width:70%;vertical-align:middle">
                  <a href="">
                    <papertitle>Task Relation Distillation and Prototypical Pseudo Label for Continual Named Entity Recognition
                    </papertitle>
                  </a>
                  <br /><br />
                  <strong>Duzhen Zhang</strong>,
                  Hongliu Li,
                  Wei Cong,
                  Rongtao Xu,
                  <br>
                  Jiahua Dong,
                  Xiuyi Chen,
                  <br /><br />
                  <strong>CIKM2023 (Oral)</strong>
                  <br>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3583780.3615075">Paper</a>
                  <a href="https://github.com/BladeDancer957/INER_RDP">Code</a>
                  <a href="slides/CIKM2023_Presentation.pdf">Slide</a>
      
                  <p align="justify">
                    Incremental Named Entity Recognition (INER) involves the sequential learning of new entity types without accessing the training data of previously learned types. However, INER faces the challenge of catastrophic forgetting specific for incremental learning, further aggravated by background shift (i.e., old and future entity types are labeled as the non-entity type in the current task). To address these challenges, we propose a method called task Relation Distillation and Prototypical pseudo label (RDP) for INER. Specifically, to tackle catastrophic forgetting, we introduce a task relation distillation scheme that serves two purposes: 1) ensuring inter-task semantic consistency across different incremental learning tasks by minimizing inter-task relation distillation loss, and 2) enhancing the model's prediction confidence by minimizing intra-task self-entropy loss. Simultaneously, to mitigate background shift, we develop a prototypical pseudo label strategy that distinguishes old entity types from the current non-entity type using the old model. This strategy generates high-quality pseudo labels by measuring the distances between token embeddings and type-wise prototypes. We conducted extensive experiments on ten INER settings of three benchmark datasets (i.e., CoNLL2003, I2B2, and OntoNotes5). The results demonstrate that our method achieves significant improvements over the previous state-of-the-art methods, with an average increase of 6.08% in Micro F1 score and 7.71% in Macro F1 score.
                  </p>
                </td>
              </tr>


              <tr>
                <td style="padding:25px;width:35%;vertical-align:middle">
                  <div class="one">
                    <img src='images/4.png' width="250">
                  </div>
                </td>
                <td style="padding:25px;width:70%;vertical-align:middle">
                  <a href="">
                    <papertitle>DualGATs:Dual Graph Attention Networks for Emotion Recognition in Conversations
                    </papertitle>
                  </a>
                  <br /><br />
                  <strong>Duzhen Zhang</strong>,
                  Feilong Chen,
                  Xiuyi Chen,
                  <br /><br />
                  <strong>ACL2023</strong>
                  <br>
                  <a href="https://aclanthology.org/2023.acl-long.408/">Paper</a>
                  <a href="https://github.com/BladeDancer957/DualGATs">Code</a>
                  <a href="posters/ACL2023_Poster.pdf">Poster</a>
      
                  <p align="justify">
                    Capturing complex contextual dependencies plays a vital role in Emotion Recognition in Conversations (ERC). Previous studies have predominantly focused on speaker-aware context modeling, overlooking the discourse structure of the conversation. In this paper, we introduce Dual Graph ATtention networks (DualGATs) to concurrently consider the complementary aspects of discourse structure and speaker-aware context, aiming for more precise ERC. Specifically, we devise a Discourse-aware GAT (DisGAT) module to incorporate discourse structural information by analyzing the discourse dependencies between utterances. Additionally, we develop a Speaker-aware GAT (SpkGAT) module to incorporate speaker-aware contextual information by considering the speaker dependencies between utterances. Furthermore, we design an interaction module that facilitates the integration of the DisGAT and SpkGAT modules, enabling the effective interchange of relevant information between the two modules. We extensively evaluate our method on four datasets, and experimental results demonstrate that our proposed DualGATs surpass state-of-the-art baselines on the majority of the datasets.                  </p>
                </td>
              </tr>

          



          </table>

          <p align="right">
            <font size="2">
              <a href="https://jonbarron.info/"> website template </a>
            </font>
          </p>


        </td>
      </tr>


  </table>
</body>

</html>